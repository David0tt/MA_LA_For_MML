{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/qb/work/hennig/hmx148/MastersThesisCode/laplace-redux'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import pycalib\n",
    "from laplace import Laplace\n",
    "\n",
    "import utils.data_utils as du\n",
    "import utils.wilds_utils as wu\n",
    "import utils.utils as util\n",
    "from utils.test import test\n",
    "from marglik_training.train_marglik import get_backend\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tueplots import bundles\n",
    "\n",
    "\n",
    "\n",
    "# Inspired by bundles.neurips2023(), but adapting font sizes for pt12 standard\n",
    "\n",
    "settings_dict = {'text.usetex': True,\n",
    "                 'font.family': 'serif',\n",
    "                 'text.latex.preamble': '\\\\renewcommand{\\\\rmdefault}{ptm}\\\\renewcommand{\\\\sfdefault}{phv}',\n",
    "                 'figure.figsize': (5.5, 3.399186938124422),\n",
    "                 'figure.constrained_layout.use': True,\n",
    "                 'figure.autolayout': False,\n",
    "                 'savefig.bbox': 'tight',\n",
    "                 'savefig.pad_inches': 0.015,\n",
    "                 'font.size': 10,\n",
    "                 'axes.labelsize': 10,\n",
    "                 'legend.fontsize': 8,\n",
    "                 'xtick.labelsize': 8,\n",
    "                 'ytick.labelsize': 8,\n",
    "                 'axes.titlesize': 10,\n",
    "                 'figure.dpi': 300}\n",
    "\n",
    "\n",
    "plt.rcParams.update(settings_dict)\n",
    "\n",
    "\n",
    "# Can use colors from bundles.rgb.\n",
    "#     tue_blue\n",
    "#     tue_brown\n",
    "#     tue_dark\n",
    "#     tue_darkblue\n",
    "#     tue_darkgreen\n",
    "#     tue_gold\n",
    "#     tue_gray\n",
    "#     tue_green\n",
    "#     tue_lightblue\n",
    "#     tue_lightgold\n",
    "#     tue_lightgreen\n",
    "#     tue_lightorange\n",
    "#     tue_mauve\n",
    "#     tue_ocre\n",
    "#     tue_orange\n",
    "#     tue_red\n",
    "#     tue_violet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def invImageNetNorm(x):\n",
    "    \"\"\" Inverts the Normalization given by:\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]) \"\"\"\n",
    "    invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "    return invTrans(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Plots with images from the test set\n",
    "# TOP: ID\n",
    "# Bottom: OOD\n",
    "\n",
    "# Left to right: different classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make overview table of the datasets:\n",
    "# Top->bottom: train, val test set\n",
    "# Left->right classes, total\n",
    "# entries: number of objects (percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_statistics(class_names, train_loader=None, IDval_loader=None, IDtest_loader=None, OODval_loader=None, OODtest_loader=None):\n",
    "    print('\\\\begin{table}\\n\\\\begin{center}\\n\\\\begin{tabular}{' + \"l|\" + \"c\" * (len(class_names) + 1) + '}')\n",
    "    print(\"    \" + \" Dataset & \" + \" & \".join(class_names) + \" & total\" + \" \\\\\\\\\\n    \\\\hline\")\n",
    "    for loader, name in zip([train_loader, IDval_loader, IDtest_loader, OODval_loader, OODtest_loader],\n",
    "                            ['train (ID)', 'val (ID)', 'test (ID)', 'val (OOD)', 'test (OOD)']):\n",
    "        if loader:\n",
    "            labels = []\n",
    "            for x, y in loader:\n",
    "                labels.append(y)\n",
    "            classes, counts = torch.concat(labels).unique(return_counts=True)\n",
    "            count_proportions = counts / counts.sum()\n",
    "            count_percentages = count_proportions * 100\n",
    "            line_string = \"    \" + name\n",
    "            for count, percentage in zip(counts, count_percentages):\n",
    "                line_string += \" & \" + f'{count} ({percentage:.1f})'\n",
    "            line_string += f\" & {counts.sum()}\"\n",
    "            line_string += \" \\\\\\\\\"\n",
    "            print(line_string)\n",
    "        else:\n",
    "            line_string = \"    \" + name + (\" & \" + \" -- \") * (len(class_names) + 1) + \" \\\\\\\\\"\n",
    "            print(line_string)\n",
    "    print(\"\\\\end{tabular}\\n\\\\end{center}\\n\\\\caption{[TODO]}\\\\label{[TODO]}\\n\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camelyon17 dataset doesn't have an in-distribution test split -- using validation split instead!\n",
      "Using the OOD validation set instead of the ID validation set\n",
      "camelyon17 dataset doesn't have an in-distribution test split -- using validation split instead!\n"
     ]
    }
   ],
   "source": [
    "dataset = 'camelyon17'\n",
    "train_loader, IDval_loader, IDtest_loader = wu.get_wilds_loaders(\n",
    "            dataset, './data', 1.0, 1, download=False, use_ood_val_set=False)\n",
    "OODtest_loader = wu.get_wilds_ood_test_loader(\n",
    "            dataset, './data', 1.0)\n",
    "_, OODval_loader, _ = wu.get_wilds_loaders(\n",
    "            dataset, './data', 1.0, 1, download=False, use_ood_val_set=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\begin{center}\n",
      "\\begin{tabular}{l|ccc}\n",
      "     Dataset & normal & tumor & total \\\\\n",
      "    \\hline\n",
      "    train (ID) & 151046 (49.9) & 151390 (50.1) & 302436 \\\\\n",
      "    val (ID) & 16952 (50.5) & 16608 (49.5) & 33560 \\\\\n",
      "    test (ID) &  --  &  --  &  --  \\\\\n",
      "    val (OOD) & 17452 (50.0) & 17452 (50.0) & 34904 \\\\\n",
      "    test (OOD) & 42527 (50.0) & 42527 (50.0) & 85054 \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\\caption{[TODO]}\\label{[TODO]}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"normal\", \"tumor\"]\n",
    "print_dataset_statistics(class_names=class_names, train_loader=train_loader, IDval_loader=IDval_loader, IDtest_loader=None, OODval_loader=OODval_loader, OODtest_loader=OODtest_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\begin{center}\n",
      "\\begin{tabular}{l|cccccccc}\n",
      "     Dataset & akiec & bcc & bkl & df & mel & nv & vasc & total \\\\\n",
      "    \\hline\n",
      "    train (ID) & 327 (3.3) & 514 (5.1) & 1099 (11.0) & 115 (1.1) & 1113 (11.1) & 6705 (66.9) & 142 (1.4) & 10015 \\\\\n",
      "    val (ID) & 8 (4.1) & 15 (7.8) & 22 (11.4) & 1 (0.5) & 21 (10.9) & 123 (63.7) & 3 (1.6) & 193 \\\\\n",
      "    test (ID) & 43 (2.8) & 93 (6.2) & 217 (14.4) & 44 (2.9) & 171 (11.3) & 909 (60.1) & 35 (2.3) & 1512 \\\\\n",
      "    val (OOD) &  --  &  --  &  --  &  --  &  --  &  --  &  --  &  --  \\\\\n",
      "    test (OOD) & 1175 (3.6) & 2926 (9.1) & 1705 (5.3) & 171 (0.5) & 4460 (13.8) & 21708 (67.2) & 169 (0.5) & 32314 \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\\caption{[TODO]}\\label{[TODO]}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Skinlesions\n",
    "train_loader, IDval_loader, IDtest_loader = du.get_ham10000_loaders('./data', batch_size=16, train_batch_size=16, num_workers=4, image_size=512)\n",
    "OODtest_loader = du.get_SkinLesions_ood_loader(None, data_path='./data', batch_size=16, num_workers=4, image_size=512)\n",
    "\n",
    "SKINLESIONS_CLASS_TO_IDX = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n",
    "class_names = SKINLESIONS_CLASS_TO_IDX.keys()\n",
    "\n",
    "print_dataset_statistics(class_names=class_names,\n",
    "                         train_loader=train_loader,\n",
    "                         IDval_loader=IDval_loader,\n",
    "                         IDtest_loader=IDtest_loader,\n",
    "                         OODtest_loader=OODtest_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the OOD validation set instead of the ID validation set\n",
      "\\begin{table}\n",
      "\\begin{center}\n",
      "\\begin{tabular}{l|cccccc}\n",
      "     Dataset & $\\bigstar \\openbigstar \\openbigstar \\openbigstar \\openbigstar$ & $\\bigstar \\bigstar \\openbigstar \\openbigstar \\openbigstar$ & $\\bigstar \\bigstar \\bigstar \\openbigstar \\openbigstar$ & $\\bigstar \\bigstar \\bigstar \\bigstar \\openbigstar$ & $\\bigstar \\bigstar \\bigstar \\bigstar \\bigstar$ & total \\\\\n",
      "    \\hline\n",
      "    train (ID) & 2648 (1.1) & 6745 (2.7) & 22903 (9.3) & 71949 (29.3) & 141257 (57.5) & 245502 \\\\\n",
      "    val (ID) & 586 (1.2) & 1323 (2.8) & 4060 (8.6) & 13010 (27.7) & 27971 (59.6) & 46950 \\\\\n",
      "    test (ID) & 572 (1.2) & 1304 (2.8) & 4496 (9.6) & 13287 (28.3) & 27291 (58.1) & 46950 \\\\\n",
      "    val (OOD) & 1413 (1.4) & 2886 (2.9) & 9315 (9.3) & 27908 (27.9) & 58528 (58.5) & 100050 \\\\\n",
      "    test (OOD) & 1643 (1.6) & 3212 (3.2) & 9972 (10.0) & 28258 (28.2) & 56965 (56.9) & 100050 \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\\caption{[TODO]}\\label{[TODO]}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Amazon\n",
    "dataset = 'amazon'\n",
    "train_loader, IDval_loader, IDtest_loader = wu.get_wilds_loaders(\n",
    "            dataset, './data', 1.0, 1, download=False, use_ood_val_set=False)\n",
    "OODtest_loader = wu.get_wilds_ood_test_loader(\n",
    "            dataset, './data', 1.0)\n",
    "_, OODval_loader, _ = wu.get_wilds_loaders(\n",
    "            dataset, './data', 1.0, 1, download=False, use_ood_val_set=True)\n",
    "\n",
    "class_names = [\"$\\\\bigstar \\\\openbigstar \\\\openbigstar \\\\openbigstar \\\\openbigstar$\",\n",
    "               \"$\\\\bigstar \\\\bigstar \\\\openbigstar \\\\openbigstar \\\\openbigstar$\",\n",
    "               \"$\\\\bigstar \\\\bigstar \\\\bigstar \\\\openbigstar \\\\openbigstar$\",\n",
    "               \"$\\\\bigstar \\\\bigstar \\\\bigstar \\\\bigstar \\\\openbigstar$\",\n",
    "               \"$\\\\bigstar \\\\bigstar \\\\bigstar \\\\bigstar \\\\bigstar$\"]\n",
    "\n",
    "print_dataset_statistics(class_names=class_names,\n",
    "                         train_loader=train_loader,\n",
    "                         IDval_loader=IDval_loader,\n",
    "                         IDtest_loader=IDtest_loader,\n",
    "                         OODval_loader=OODval_loader,\n",
    "                         OODtest_loader=OODtest_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/qb/work/hennig/hmx148/MastersThesisCode/laplace-redux'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_num_images_from_dataset(class_names, IDtest_loader, OODtest_loader, dataset_name, num_images=20):\n",
    "    savedir = f\"./results/images/{dataset_name}\"\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "\n",
    "    for loader, condition_name in zip([IDtest_loader, OODtest_loader], [\"ID\", \"OOD\"]):\n",
    "        for class_id, class_name in enumerate(class_names):\n",
    "            imgs = []\n",
    "            img_found_num = 0\n",
    "            for x, y in loader:\n",
    "                if img_found_num == num_images:\n",
    "                    break\n",
    "                if torch.any(y == class_id):\n",
    "                    img = x[y == class_id][0]\n",
    "                    imgs.append(img)\n",
    "                    img_found_num += 1\n",
    "\n",
    "                    img = invImageNetNorm(img).permute(1,2,0)\n",
    "                    # img = invImageNetNorm(img) # .permute(1,2,0)\n",
    "\n",
    "                    img = img.numpy()\n",
    "                    img = (img * 255).astype('uint8')\n",
    "                    # print(img)\n",
    "\n",
    "                    pil_img = Image.fromarray(img, 'RGB')\n",
    "\n",
    "                    filename = f'{condition_name}_{class_name}_{img_found_num}.png'\n",
    "                    pil_img.save(os.path.join(savedir, filename), 'PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camelyon17 dataset doesn't have an in-distribution test split -- using validation split instead!\n",
      "Using the OOD validation set instead of the ID validation set\n",
      "camelyon17 dataset doesn't have an in-distribution test split -- using validation split instead!\n"
     ]
    }
   ],
   "source": [
    "# Cameylon17\n",
    "class_names = [\"normal\", \"tumor\"]\n",
    "dataset = 'camelyon17'\n",
    "train_loader, IDval_loader, IDtest_loader = wu.get_wilds_loaders(\n",
    "            dataset, './data', 1.0, 1, download=False, use_ood_val_set=False)\n",
    "OODtest_loader = wu.get_wilds_ood_test_loader(\n",
    "            dataset, './data', 1.0)\n",
    "_, OODval_loader, _ = wu.get_wilds_loaders(\n",
    "            dataset, './data', 1.0, 1, download=False, use_ood_val_set=True)\n",
    "save_num_images_from_dataset(class_names=class_names, IDtest_loader=IDtest_loader, OODtest_loader=OODtest_loader, dataset_name=\"Camelyon17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Skinlesions\n",
    "train_loader, IDval_loader, IDtest_loader = du.get_ham10000_loaders('./data', batch_size=16, train_batch_size=16, num_workers=4, image_size=512)\n",
    "OODtest_loader = du.get_SkinLesions_ood_loader(None, data_path='./data', batch_size=16, num_workers=4, image_size=512)\n",
    "\n",
    "SKINLESIONS_CLASS_TO_IDX = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n",
    "class_names = SKINLESIONS_CLASS_TO_IDX.keys()\n",
    "\n",
    "\n",
    "save_num_images_from_dataset(class_names=class_names, IDtest_loader=IDtest_loader, OODtest_loader=OODtest_loader, dataset_name=\"SkinLesions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
