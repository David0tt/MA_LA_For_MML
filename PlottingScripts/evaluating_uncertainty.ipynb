{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE plot with the errorbars given by the confidence distribution in the bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import pycalib\n",
    "from laplace import Laplace\n",
    "\n",
    "import utils.data_utils as du\n",
    "import utils.wilds_utils as wu\n",
    "import utils.utils as util\n",
    "from utils.test import test\n",
    "from marglik_training.train_marglik import get_backend\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tueplots import bundles\n",
    "\n",
    "\n",
    "\n",
    "# Inspired by bundles.neurips2023(), but adapting font sizes for pt12 standard\n",
    "\n",
    "settings_dict = {'text.usetex': True,\n",
    "                 'font.family': 'serif',\n",
    "                 'text.latex.preamble': '\\\\renewcommand{\\\\rmdefault}{ptm}\\\\renewcommand{\\\\sfdefault}{phv}',\n",
    "                 'figure.figsize': (5.5, 3.399186938124422),\n",
    "                 'figure.constrained_layout.use': True,\n",
    "                 'figure.autolayout': False,\n",
    "                 'savefig.bbox': 'tight',\n",
    "                 'savefig.pad_inches': 0.015,\n",
    "                 'font.size': 10,\n",
    "                 'axes.labelsize': 10,\n",
    "                 'legend.fontsize': 8,\n",
    "                 'xtick.labelsize': 8,\n",
    "                 'ytick.labelsize': 8,\n",
    "                 'axes.titlesize': 10,\n",
    "                 'figure.dpi': 300}\n",
    "\n",
    "\n",
    "plt.rcParams.update(settings_dict)\n",
    "\n",
    "\n",
    "# Can use colors from bundles.rgb.\n",
    "#     tue_blue\n",
    "#     tue_brown\n",
    "#     tue_dark\n",
    "#     tue_darkblue\n",
    "#     tue_darkgreen\n",
    "#     tue_gold\n",
    "#     tue_gray\n",
    "#     tue_green\n",
    "#     tue_lightblue\n",
    "#     tue_lightgold\n",
    "#     tue_lightgreen\n",
    "#     tue_lightorange\n",
    "#     tue_mauve\n",
    "#     tue_ocre\n",
    "#     tue_orange\n",
    "#     tue_red\n",
    "#     tue_violet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cov(points):\n",
    "    B, N, D = points.size()\n",
    "    mean = points.mean(dim=1).unsqueeze(1)\n",
    "    diffs = (points - mean).reshape(B * N, D)\n",
    "    prods = torch.bmm(diffs.unsqueeze(2), diffs.unsqueeze(1)).reshape(B, N, D, D)\n",
    "    bcov = prods.sum(dim=1) / (N - 1)  # Unbiased estimate\n",
    "    return bcov  # (B, D, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_samples(mean, var, n_samples, generator=None):\n",
    "    \"\"\"Produce samples from a batch of Normal distributions either parameterized\n",
    "    by a diagonal or full covariance given by `var`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : torch.Tensor\n",
    "        `(batch_size, output_dim)`\n",
    "    var : torch.Tensor\n",
    "        (co)variance of the Normal distribution\n",
    "        `(batch_size, output_dim, output_dim)` or `(batch_size, output_dim)`\n",
    "    generator : torch.Generator\n",
    "        random number generator\n",
    "    \"\"\"\n",
    "    assert mean.ndim == 2, 'Invalid input shape of mean, should be 2-dimensional.'\n",
    "    _, output_dim = mean.shape\n",
    "    randn_samples = torch.randn((output_dim, n_samples), device=mean.device, \n",
    "                                dtype=mean.dtype, generator=generator)\n",
    "    \n",
    "    if mean.shape == var.shape:\n",
    "        # diagonal covariance\n",
    "        scaled_samples = var.sqrt().unsqueeze(-1) * randn_samples.unsqueeze(0)\n",
    "        return (mean.unsqueeze(-1) + scaled_samples).permute((2, 0, 1))\n",
    "    elif mean.shape == var.shape[:2] and var.shape[-1] == mean.shape[1]:\n",
    "        # full covariance\n",
    "        scale = torch.linalg.cholesky(var)\n",
    "        scaled_samples = torch.matmul(scale, randn_samples.unsqueeze(0))  # expand batch dim\n",
    "        return (mean.unsqueeze(-1) + scaled_samples).permute((2, 0, 1))\n",
    "    else:\n",
    "        raise ValueError('Invalid input shapes.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confs_preds_variances_ypreds(f_mu, f_var, y_true, n_samples = 10000, generator = None, batchsize = 128):\n",
    "    # For all images, calculate the conf and covariance\n",
    "    # To do this sample from distribution\n",
    "\n",
    "    confs_list = []\n",
    "    preds_list = []\n",
    "    variances_list = []\n",
    "    y_preds_list = []\n",
    "\n",
    "    s_list = list(range(0, y_true.shape[0] + batchsize, batchsize))\n",
    "    # s_list = list(range(0, 1000, batchsize))\n",
    "    for start, stop in tqdm(zip(s_list[:-1], s_list[1:])):\n",
    "        f_mu_now = f_mu[start:stop]\n",
    "        f_var_now = f_var[start:stop]\n",
    "        \n",
    "        f_samples = normal_samples(f_mu_now, f_var_now, n_samples, generator)\n",
    "        y_prob = torch.softmax(f_samples, dim=-1)\n",
    "\n",
    "        covariances = batch_cov(y_prob.permute(1,0,2))\n",
    "\n",
    "        y_pred = y_prob.mean(dim=0)\n",
    "\n",
    "        confs, preds = torch.max(y_pred, 1)\n",
    "\n",
    "        variances = torch.tensor([c[preds[i], preds[i]] for i, c in enumerate(covariances)])\n",
    "\n",
    "        confs_list.append(confs)\n",
    "        preds_list.append(preds)\n",
    "        variances_list.append(variances)\n",
    "        y_preds_list.append(y_pred)\n",
    "\n",
    "\n",
    "    confs_list = torch.cat(confs_list)\n",
    "    preds_list = torch.cat(preds_list)\n",
    "    variances_list = torch.cat(variances_list)\n",
    "    y_preds_list = torch.cat(y_preds_list)\n",
    "\n",
    "    return confs_list, preds_list, variances_list, y_preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ece(outputs, labels, n_bins=10):\n",
    "    \"\"\"\n",
    "    Calculates the Expected Calibration Error of a model.\n",
    "    (This isn't necessary for temperature scaling, just a cool metric).\n",
    "    The input to this loss are the model output softmax scores.\n",
    "    This divides the confidence outputs into equally-sized interval bins.\n",
    "    In each bin, we compute the confidence gap:\n",
    "    bin_gap = | avg_confidence_in_bin - accuracy_in_bin |\n",
    "    We then return a weighted average of the gaps, based on the number\n",
    "    of samples in each bin\n",
    "    See: Naeini, Mahdi Pakdaman, Gregory F. Cooper, and Milos Hauskrecht.\n",
    "    \"Obtaining Well Calibrated Probabilities Using Bayesian Binning.\" AAAI.\n",
    "    2015.\n",
    "    \"\"\"\n",
    "\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    softmaxes = outputs\n",
    "    confidences, predictions = torch.max(softmaxes, 1)\n",
    "    accuracies = predictions.eq(labels)\n",
    "\n",
    "    ece = torch.zeros(1, device=outputs.device)\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated |confidence - accuracy| in each bin\n",
    "        in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        if prop_in_bin.item() > 0:\n",
    "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "    return ece.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import argparse\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import pycalib\n",
    "from laplace import Laplace\n",
    "\n",
    "import utils.data_utils as du\n",
    "import utils.wilds_utils as wu\n",
    "import utils.utils as util\n",
    "from utils.test import test\n",
    "from marglik_training.train_marglik import get_backend\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cov(points):\n",
    "    B, N, D = points.size()\n",
    "    mean = points.mean(dim=1).unsqueeze(1)\n",
    "    diffs = (points - mean).reshape(B * N, D)\n",
    "    prods = torch.bmm(diffs.unsqueeze(2), diffs.unsqueeze(1)).reshape(B, N, D, D)\n",
    "    bcov = prods.sum(dim=1) / (N - 1)  # Unbiased estimate\n",
    "    return bcov  # (B, D, D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reliability_diagram_with_conf_uncertainty(y_pred, variances, labels, n_bins=40, title_name=\"\"):\n",
    "    \"\"\"\n",
    "    outputs - a torch tensor (size n x num_classes) with the output of a model (after Softmax)\n",
    "    labels - a torch tensor (size n) with the labels\n",
    "    \"\"\"\n",
    "\n",
    "    # outputs = y_prob.mean(axis=0)\n",
    "    outputs = y_pred\n",
    "\n",
    "    softmaxes = outputs\n",
    "    confidences, predictions = softmaxes.max(1)\n",
    "    accuracies = torch.eq(predictions, labels)\n",
    "    overall_accuracy = (predictions==labels).sum().item()/len(labels)\n",
    "    \n",
    "    # Reliability diagram\n",
    "    bins = torch.linspace(0, 1, n_bins + 1)\n",
    "    width = 1.0 / n_bins\n",
    "    bin_centers = np.linspace(0, 1.0 - width, n_bins) + width / 2\n",
    "    bin_indices = [confidences.ge(bin_lower) * confidences.lt(bin_upper) for bin_lower, bin_upper in zip(bins[:-1], bins[1:])]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # # mean_conf in each bin (with calculation from the individual variance)\n",
    "    # # To prevent crashing, do it in batches:\n",
    "    # s_list = list(range(0, y_prob.shape[1] + 10000, 5000))\n",
    "    # covariances = torch.cat([batch_cov(y_prob[:, start:stop].permute(1,0,2)) for start, stop in zip(s_list[:-1], s_list[1:])])\n",
    "    # max_class_variances = torch.tensor([c[predictions[i], predictions[i]] for i, c in enumerate(covariances)])\n",
    "    # # mean_variance = torch.tensor([c[preds[i], preds[i]] for i, c in enumerate(covariances)]).mean().item()\n",
    "\n",
    "    max_class_variances = variances\n",
    "\n",
    "    bin_mean_variances = np.array([max_class_variances[bin_index].mean() for bin_index in bin_indices])\n",
    "    bin_counts = np.array([max_class_variances[bin_index].shape[0] for bin_index in bin_indices])\n",
    "    bin_counts = np.maximum(bin_counts, 1) # Solve division by zero error in empty bins\n",
    "    bin_mean_variances = bin_mean_variances * (1 / bin_counts)\n",
    "\n",
    "    bin_mean_2stds = np.sqrt(bin_mean_variances) * 2\n",
    "\n",
    "    # # p-value of an accuracy as extreme or more extreme than the observed one in the respective bin\n",
    "    # idx = predictions.unsqueeze(0).repeat(y_prob.shape[0], 1).unsqueeze(2)\n",
    "    # selected_class_confs = torch.gather(y_prob, 2, idx).squeeze()\n",
    "    # bin_p_values = []\n",
    "    # for bin_index in bin_indices:\n",
    "    #     bin_y_prob = y_prob[:, bin_index, :]\n",
    "    #     # check for sidedness:\n",
    "    #     bin_acc = torch.mean(accuracies[bin_index].float())\n",
    "    #     bin_conf = torch.mean(confidences[bin_index].float())\n",
    "    #     bin_selected_class_confs = selected_class_confs[:, bin_index]\n",
    "    #     bin_mean_confs_dist = bin_selected_class_confs.mean(axis=1)\n",
    "    #     if bin_acc < bin_conf:\n",
    "    #         bin_p_value = torch.mean((bin_mean_confs_dist < bin_acc).float())\n",
    "    #     else:\n",
    "    #         bin_p_value = torch.mean((bin_mean_confs_dist > bin_acc).float())\n",
    "    #     bin_p_values.append(bin_p_value)\n",
    "    # bin_p_values = np.array(bin_p_values)\n",
    "    # avg_p_value = bin_p_values.mean()    \n",
    "\n",
    "\n",
    "\n",
    "    bin_corrects = np.array([ torch.mean(accuracies[bin_index].float()) for bin_index in bin_indices])\n",
    "    bin_scores = np.array([ torch.mean(confidences[bin_index].float()) for bin_index in bin_indices])\n",
    "    bin_corrects = np.nan_to_num(bin_corrects)\n",
    "    bin_scores = np.nan_to_num(bin_scores)\n",
    "    \n",
    "    # plt.figure(0, figsize=(8, 8))\n",
    "    # figsize = (plt.rcParams[\"figure.figsize\"][1], plt.rcParams[\"figure.figsize\"][1])\n",
    "    # figsize = (4.5, 4.5)\n",
    "    figsize = (2.75, 2.75)\n",
    "    plt.figure(0, figsize=figsize)\n",
    "    gap = np.array(bin_scores - bin_corrects)\n",
    "    \n",
    "    confs = plt.bar(bin_centers, bin_corrects, color=[0, 0, 1], width=width, ec='black')\n",
    "    bin_corrects = np.nan_to_num(np.array([bin_correct for bin_correct in bin_corrects]))\n",
    "    gaps = plt.bar(bin_centers, gap, bottom=bin_corrects, color=[1, 0.7, 0.7], alpha=0.5, width=width, hatch='//', edgecolor='r')\n",
    "    # errorbars = plt.errorbar(bin_centers, bin_corrects, fmt=\".\", yerr=bin_mean_2stds)\n",
    "    # errorbars = plt.errorbar(bin_centers, bin_centers, fmt=\".\", yerr=bin_mean_2stds)\n",
    "    errorbars = plt.errorbar(bin_centers, bin_centers, fmt=\".\", xerr=bin_mean_2stds)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "    # plt.legend([confs, gaps, errorbars], ['Accuracy', 'Gap', '2 stds of the confidence'], loc='upper left', fontsize='x-large')\n",
    "    plt.legend([confs, gaps, errorbars], ['Accuracy', 'Gap', r'$2\\sigma$ of the Confidence'], loc='upper left')\n",
    "\n",
    "    ece = calculate_ece(outputs, labels)\n",
    "\n",
    "    # Clean up\n",
    "    # bbox_props = dict(boxstyle=\"square\", fc=\"lightgrey\", ec=\"gray\", lw=1.5)\n",
    "    # plt.text(0.95, 0.05, \"ECE: {:.4f}\".format(ece), ha=\"right\", va=\"bottom\", size=plt.rcParams[\"font.size\"], weight = 'normal', bbox=bbox_props)\n",
    "    # plt.text(0.17, 0.64, \"AVG p-value: {:.8f}\\n(for an accuracy as\\n extreme or more\\n extreme as the one\\n observed wrt\\n the mean_confidence\\n distribution in each bin)\".format(avg_p_value), ha=\"center\", va=\"center\", size=14, weight = 'normal', bbox=bbox_props)\n",
    "\n",
    "    # plt.title(f\"{title_name}\", size=22)\n",
    "    # plt.ylabel(\"Accuracy\",  size=18)\n",
    "    # plt.xlabel(\"Confidence\",  size=18)\n",
    "    plt.title(f\"{title_name}\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Confidence\")\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    # plt.savefig(f\"plotting_uncertainty_pr/reliability_plots/{title_name}.png\")\n",
    "    # plt.show()\n",
    "    # return ece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camelyon17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliabilityDiagramsSavedir = \"./results/img/Results/ReliabilityPlotsWithUncertainty\"\n",
    "if not os.path.exists(reliabilityDiagramsSavedir):\n",
    "    os.makedirs(reliabilityDiagramsSavedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/camelyon17/',\n",
    "                        './results/predictive_distributions/camelyon17_ts/',\n",
    "                        './results/predictive_distributions/camelyon17_scaling/',\n",
    "                        # './results/predictive_distributions/camelyon17_diagadd_fitted/',\n",
    "                        # './results/predictive_distributions/camelyon17_diagscaling_fitted/',\n",
    "                        # './results/predictive_distributions/camelyon17_scaling_only_simple_scaling_fitted/',\n",
    "                        './results/predictive_distributions/camelyon17_ts_and_scaling_fitted/',\n",
    "                        # './results/predictive_distributions/camelyon17_ts_and_scaling_fitted_on_ood_val/',\n",
    "                        # './results/predictive_distributions/camelyon17_ts_and_scaling_fitted_model6/',\n",
    "                        # './results/predictive_distributions/camelyon17_ts_and_scaling_fitted_on_ood_val_model6/'\n",
    "]\n",
    "\n",
    "title_names = [\"LLLA\", \"LLLA+WITS\", \"LLLA+CVS\", \"LLLA+WITS+CVS\"]\n",
    "\n",
    "for DISTRIBUTIONS_DIRECTORY, title_name in zip(distribution_directories, title_names):\n",
    "    for DATASET in ['camelyon17-id', 'camelyon17-ood']:\n",
    "        print(\"### \", DISTRIBUTIONS_DIRECTORY, \" - \", DATASET)\n",
    "        y_true = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_true_\" + DATASET + \".pt\"))\n",
    "        # y_prob = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_prob_\" + DATASET + \".pt\"))\n",
    "\n",
    "        f_mu = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_mu_\" + DATASET + \".pt\"))\n",
    "        f_var = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_var_\" + DATASET + \".pt\"))\n",
    "\n",
    "        confs, preds, variances, y_pred = calculate_confs_preds_variances_ypreds(f_mu, f_var, y_true)\n",
    "\n",
    "        DatasetTranslationDict = {'camelyon17-id': 'WILDS-Camelyon17 (ID)', 'camelyon17-ood': 'WILDS-Camelyon17 (OOD)', 'amazon-id': 'WILDS-Amazon (ID)', 'amazon-ood': 'WILDS-Amazon (OOD)', 'SkinLesions-id': 'SkinLesions (ID)', 'SkinLesions-ood': 'SkinLesions (OOD)'}\n",
    "        title = f'{title_name} on {DatasetTranslationDict[DATASET]}'\n",
    "        make_reliability_diagram_with_conf_uncertainty(y_pred, variances, y_true, title_name=title)\n",
    "        plt.savefig(os.path.join(reliabilityDiagramsSavedir, f'{title_name}_{DATASET}.pdf'))\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camelyon17 - ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/camelyon17_resnet50/', # TODO or use:\n",
    "                            # './results/predictive_distributions/camelyon17_ts/', #TODO or use this one?\n",
    "                            './results/predictive_distributions/camelyon17_resnet50_ts_and_scaling_fitted']\n",
    "\n",
    "title_names = [\"LLLA\", \"LLLA+WITS+CVS\"]\n",
    "\n",
    "\n",
    "for DISTRIBUTIONS_DIRECTORY, title_name in zip(distribution_directories, title_names):\n",
    "    for DATASET in ['camelyon17-id', 'camelyon17-ood']:\n",
    "        print(\"### \", DISTRIBUTIONS_DIRECTORY, \" - \", DATASET)\n",
    "        y_true = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_true_\" + DATASET + \".pt\"))\n",
    "        # y_prob = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_prob_\" + DATASET + \".pt\"))\n",
    "\n",
    "        f_mu = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_mu_\" + DATASET + \".pt\"))\n",
    "        f_var = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_var_\" + DATASET + \".pt\"))\n",
    "\n",
    "        confs, preds, variances, y_pred = calculate_confs_preds_variances_ypreds(f_mu, f_var, y_true)\n",
    "\n",
    "        DatasetTranslationDict = {'camelyon17-id': 'WILDS-Camelyon17 (ID)', 'camelyon17-ood': 'WILDS-Camelyon17 (OOD)', 'amazon-id': 'WILDS-Amazon (ID)', 'amazon-ood': 'WILDS-Amazon (OOD)', 'SkinLesions-id': 'SkinLesions (ID)', 'SkinLesions-ood': 'SkinLesions (OOD)'}\n",
    "        DatasetTranslationDict = {'camelyon17-id': 'Camelyon17 (ID)', 'camelyon17-ood': 'Camelyon17 (OOD)', 'amazon-id': 'WILDS-Amazon (ID)', 'amazon-ood': 'WILDS-Amazon (OOD)', 'SkinLesions-id': 'SkinLesions (ID)', 'SkinLesions-ood': 'SkinLesions (OOD)'}\n",
    "        title = f'{title_name} with ResNet50 on {DatasetTranslationDict[DATASET]}'\n",
    "        make_reliability_diagram_with_conf_uncertainty(y_pred, variances, y_true, title_name=title)\n",
    "        plt.savefig(os.path.join(reliabilityDiagramsSavedir, f'{title_name}_{DATASET}_resnet50.pdf'))\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/amazon/',\n",
    "                            './results/predictive_distributions/amazon_scaling/',\n",
    "                            './results/predictive_distributions/amazon_ts/',\n",
    "                            './results/predictive_distributions/amazon_ts_and_scaling_fitted/',\n",
    "]\n",
    "\n",
    "title_names = [\"LLLA\", \"LLLA+CVS\", \"LLLA+WITS\", \"LLLA+WITS+CVS\"]\n",
    "\n",
    "\n",
    "for DISTRIBUTIONS_DIRECTORY, title_name in zip(distribution_directories, title_names):\n",
    "    for DATASET in ['amazon-id', 'amazon-ood']:\n",
    "        print(\"### \", DISTRIBUTIONS_DIRECTORY, \" - \", DATASET)\n",
    "        y_true = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_true_\" + DATASET + \".pt\"))\n",
    "        # y_prob = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_prob_\" + DATASET + \".pt\"))\n",
    "\n",
    "        f_mu = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_mu_\" + DATASET + \".pt\"))\n",
    "        f_var = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_var_\" + DATASET + \".pt\"))\n",
    "\n",
    "        confs, preds, variances, y_pred = calculate_confs_preds_variances_ypreds(f_mu, f_var, y_true)\n",
    "\n",
    "        DatasetTranslationDict = {'camelyon17-id': 'WILDS-Camelyon17 (ID)', 'camelyon17-ood': 'WILDS-Camelyon17 (OOD)', 'amazon-id': 'WILDS-Amazon (ID)', 'amazon-ood': 'WILDS-Amazon (OOD)', 'SkinLesions-id': 'SkinLesions (ID)', 'SkinLesions-ood': 'SkinLesions (OOD)'}\n",
    "        title = f'{title_name} on {DatasetTranslationDict[DATASET]}'\n",
    "        make_reliability_diagram_with_conf_uncertainty(y_pred, variances, y_true, title_name=title)\n",
    "        plt.savefig(os.path.join(reliabilityDiagramsSavedir, f'{title_name}_{DATASET}.pdf'))\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkinLesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/SkinLesions/',\n",
    "                            './results/predictive_distributions/SkinLesions_ts/',\n",
    "                            './results/predictive_distributions/SkinLesions_scaling/',\n",
    "                            './results/predictive_distributions/SkinLesions_ts_and_scaling_fitted/',\n",
    "                            ]\n",
    "\n",
    "title_names = [\"LLLA\", \"LLLA+WITS\", \"LLLA+CVS\", \"LLLA+WITS+CVS\"]\n",
    "\n",
    "for DISTRIBUTIONS_DIRECTORY, title_name in zip(distribution_directories, title_names):\n",
    "    for DATASET in ['SkinLesions-id', 'SkinLesions-ood']:\n",
    "        print(\"### \", DISTRIBUTIONS_DIRECTORY, \" - \", DATASET)\n",
    "        y_true = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_true_\" + DATASET + \".pt\"))\n",
    "        # y_prob = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_prob_\" + DATASET + \".pt\"))\n",
    "\n",
    "        f_mu = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_mu_\" + DATASET + \".pt\"))\n",
    "        f_var = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_var_\" + DATASET + \".pt\"))\n",
    "\n",
    "        confs, preds, variances, y_pred = calculate_confs_preds_variances_ypreds(f_mu, f_var, y_true)\n",
    "\n",
    "        DatasetTranslationDict = {'camelyon17-id': 'WILDS-Camelyon17 (ID)', 'camelyon17-ood': 'WILDS-Camelyon17 (OOD)', 'amazon-id': 'WILDS-Amazon (ID)', 'amazon-ood': 'WILDS-Amazon (OOD)', 'SkinLesions-id': 'SkinLesions (ID)', 'SkinLesions-ood': 'SkinLesions (OOD)'}\n",
    "        title = f'{title_name} on {DatasetTranslationDict[DATASET]}'\n",
    "        make_reliability_diagram_with_conf_uncertainty(y_pred, variances, y_true, title_name=title)\n",
    "        plt.savefig(os.path.join(reliabilityDiagramsSavedir, f'{title_name}_{DATASET}.pdf'))\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot confidence-accuracy gap by size of uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice Plots PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import argparse\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import pycalib\n",
    "from laplace import Laplace\n",
    "\n",
    "import utils.data_utils as du\n",
    "import utils.wilds_utils as wu\n",
    "import utils.utils as util\n",
    "from utils.test import test\n",
    "from marglik_training.train_marglik import get_backend\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cov(points):\n",
    "    B, N, D = points.size()\n",
    "    mean = points.mean(dim=1).unsqueeze(1)\n",
    "    diffs = (points - mean).reshape(B * N, D)\n",
    "    prods = torch.bmm(diffs.unsqueeze(2), diffs.unsqueeze(1)).reshape(B, N, D, D)\n",
    "    bcov = prods.sum(dim=1) / (N - 1)  # Unbiased estimate\n",
    "    return bcov  # (B, D, D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_acc_gap_by_uncertainty_to_ax(ax, y_pred, variances, labels, n_bins=10, marker='o'):\n",
    "    \"\"\"\n",
    "    outputs - a torch tensor (size n x num_classes) with the output of a model (after Softmax)\n",
    "    labels - a torch tensor (size n) with the labels\n",
    "    \"\"\"\n",
    "\n",
    "    # outputs = y_prob.mean(axis=0)\n",
    "    outputs = y_pred\n",
    "\n",
    "    softmaxes = outputs\n",
    "    confidences, predictions = softmaxes.max(1)\n",
    "    accuracies = torch.eq(predictions, labels)\n",
    "    overall_accuracy = (predictions==labels).sum().item()/len(labels)\n",
    "    \n",
    "    # Reliability diagram\n",
    "    bins = torch.linspace(0, 1, n_bins + 1)\n",
    "    width = 1.0 / n_bins\n",
    "    bin_centers = np.linspace(0, 1.0 - width, n_bins) + width / 2\n",
    "    bin_indices = [confidences.ge(bin_lower) * confidences.lt(bin_upper) for bin_lower, bin_upper in zip(bins[:-1], bins[1:])]\n",
    "    \n",
    "\n",
    "\n",
    "    # # mean_conf in each bin (with calculation from the individual variance)\n",
    "    # # To prevent crashing, do it in batches:\n",
    "    # s_list = list(range(0, y_prob.shape[1] + 10000, 5000))\n",
    "    # covariances = torch.cat([batch_cov(y_prob[:, start:stop].permute(1,0,2)) for start, stop in zip(s_list[:-1], s_list[1:])])\n",
    "    # max_class_variances = torch.tensor([c[predictions[i], predictions[i]] for i, c in enumerate(covariances)])\n",
    "    # # mean_variance = torch.tensor([c[preds[i], preds[i]] for i, c in enumerate(covariances)]).mean().item()\n",
    "\n",
    "    max_class_variances = variances\n",
    "\n",
    "    bin_mean_variances = np.array([max_class_variances[bin_index].mean() for bin_index in bin_indices])\n",
    "    bin_counts = np.array([max_class_variances[bin_index].shape[0] for bin_index in bin_indices])\n",
    "    bin_counts = np.maximum(bin_counts, 1) # Solve division by zero error in empty bins\n",
    "    bin_mean_variances = bin_mean_variances * (1 / bin_counts)\n",
    "\n",
    "    bin_mean_2stds = np.sqrt(bin_mean_variances) * 2\n",
    "\n",
    "    \n",
    "    bin_corrects = np.array([ torch.mean(accuracies[bin_index].float()) for bin_index in bin_indices])\n",
    "    bin_scores = np.array([ torch.mean(confidences[bin_index].float()) for bin_index in bin_indices])\n",
    "    bin_corrects = np.nan_to_num(bin_corrects)\n",
    "    bin_scores = np.nan_to_num(bin_scores)\n",
    "    \n",
    "    # plt.figure(0, figsize=(8, 8))\n",
    "    gap = np.array(bin_scores - bin_corrects)\n",
    "\n",
    "    gap = np.abs(gap)\n",
    "    \n",
    "    # confs = plt.bar(bin_centers, bin_corrects, color=[0, 0, 1], width=width, ec='black')\n",
    "    # bin_corrects = np.nan_to_num(np.array([bin_correct for bin_correct in bin_corrects]))\n",
    "\n",
    "\n",
    "#     colors = plt.get_cmap('viridis')(bin_counts/bin_counts.max())\n",
    "    # colors = bundles.rgb.tue_blue # Plot without color\n",
    "    # colors = bundles.rgb.tue_violet # Plot without color\n",
    "    colors = bundles.rgb.tue_darkblue # Plot without color\n",
    "\n",
    "    # print(bin_counts)\n",
    "    # ax.plot(bin_mean_2stds, gap, \"o\") # TODO changed\n",
    "    ax.scatter(bin_mean_2stds, gap, c = colors, marker=marker)\n",
    "    # ax.scatter(bin_mean_variances, gap, c = colors)\n",
    "\n",
    "    # # Calculate Correlation\n",
    "    # empty_ids = np.logical_not(np.isnan(bin_mean_2stds))\n",
    "    # corr = np.corrcoef(np.vstack([gap[empty_ids], bin_mean_2stds[empty_ids]]))[0][1]\n",
    "    # alpha=0.8\n",
    "    # bbox_props = dict(boxstyle=\"square\", fc=\"lightgrey\", ec=\"gray\", lw=1.5, alpha=alpha)\n",
    "    # ax.text(0.95, 0.05, r\"$\\rho$: \" + \"{:.3f}\".format(corr), ha=\"right\", va=\"bottom\", size=plt.rcParams[\"font.size\"], \n",
    "    #         weight = 'normal', bbox=bbox_props, transform=ax.transAxes)\n",
    "\n",
    "\n",
    "    # gaps = plt.bar(bin_centers, gap, bottom=bin_corrects, color=[1, 0.7, 0.7], alpha=0.5, width=width, hatch='//', edgecolor='r')\n",
    "    # errorbars = plt.errorbar(bin_centers, bin_corrects, fmt=\".\", yerr=bin_mean_2stds)\n",
    "    \n",
    "    # plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "    # plt.legend([confs, gaps, errorbars], ['Accuracy', 'Gap', '2 stds of the confidence'], loc='upper left', fontsize='x-large')\n",
    "\n",
    "\n",
    "    # # Clean up\n",
    "    # bbox_props = dict(boxstyle=\"square\", fc=\"lightgrey\", ec=\"gray\", lw=1.5)\n",
    "    # plt.text(0.17, 0.82, \"ECE: {:.4f}\".format(ece), ha=\"center\", va=\"center\", size=20, weight = 'normal', bbox=bbox_props)\n",
    "\n",
    "    # plt.title(\"Reliability Diagram; TODO note that stds of the conf are on the acc axis\", size=22)\n",
    "    # plt.ylabel(r'$\\vert$Conf - Acc$\\vert$',  size=18)\n",
    "    # plt.xlabel(\"2 stds of conf mean\",  size=18)\n",
    "    # plt.xlim(0,1)\n",
    "    # plt.ylim(0,1)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, figuretitle=\"\", justPlotTop=False, addXLabel=False):\n",
    "    if justPlotTop:\n",
    "        figsize =  (4, 2.2) if addXLabel else (4, 2)\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        axs = [axs]\n",
    "    else:\n",
    "        # TODO try size:\n",
    "        # figsize = (plt.rcParams[\"figure.figsize\"][1], plt.rcParams[\"figure.figsize\"][1])\n",
    "        # figsize = (plt.rcParams[\"figure.figsize\"][0], plt.rcParams[\"figure.figsize\"][0])\n",
    "        figsize = (4, 3.8)\n",
    "        fig, axs = plt.subplots(2, 2)\n",
    "    fig.set_size_inches(figsize)\n",
    "\n",
    "    for ax_j, (DISTRIBUTIONS_DIRECTORY, distribution_name) in enumerate(zip(distribution_directories, distribution_names)):\n",
    "        if justPlotTop and ax_j >= 1:\n",
    "                pass\n",
    "        else:\n",
    "            for ax_i, DATASET in enumerate(dataset_names):\n",
    "                print(\"### \", DISTRIBUTIONS_DIRECTORY, \" - \", DATASET)\n",
    "                y_true = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_true_\" + DATASET + \".pt\"))\n",
    "                # y_prob = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_prob_\" + DATASET + \".pt\"))\n",
    "\n",
    "                f_mu = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_mu_\" + DATASET + \".pt\"))\n",
    "                f_var = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_var_\" + DATASET + \".pt\"))\n",
    "\n",
    "                confs, preds, variances, y_pred = calculate_confs_preds_variances_ypreds(f_mu, f_var, y_true)\n",
    "\n",
    "                ax = axs[ax_j][ax_i]\n",
    "                plot_conf_acc_gap_by_uncertainty_to_ax(ax, y_pred, variances, y_true, n_bins=100)\n",
    "\n",
    "                if ax_j == 0:\n",
    "                    DatasetTranslationDict = {'camelyon17-id': 'WILDS-Camelyon17 (ID)', 'camelyon17-ood': 'WILDS-Camelyon17 (OOD)', 'amazon-id': 'WILDS-Amazon (ID)', 'amazon-ood': 'WILDS-Amazon (OOD)', 'SkinLesions-id': 'SkinLesions (ID)', 'SkinLesions-ood': 'SkinLesions (OOD)'}\n",
    "                    ax.set_title(DatasetTranslationDict[DATASET])\n",
    "                if ax_i == 0:\n",
    "                    if justPlotTop:\n",
    "                        ax.set_ylabel(r'$\\vert$Conf - Acc$\\vert$')\n",
    "                    else:\n",
    "                        ax.set_ylabel(distribution_name + \"\\n\" + r'$\\vert$Conf - Acc$\\vert$')\n",
    "                if ax_j == 1 or addXLabel:\n",
    "                    ax.set_xlabel(r\"$2 \\sigma$ of confidence mean\")\n",
    "    fig.suptitle(figuretitle)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir_confAccGapByUncertainty = \"./results/img/Results/ConfAccGapByUncertainty\"\n",
    "if not os.path.exists(savedir_confAccGapByUncertainty):\n",
    "    os.makedirs(savedir_confAccGapByUncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/camelyon17/', # TODO or use:\n",
    "                            # './results/predictive_distributions/camelyon17_ts/', #TODO or use this one?\n",
    "                            './results/predictive_distributions/camelyon17_ts_and_scaling_fitted']\n",
    "distribution_names = [\"LLLA\", \"LLLA+WITS+CVS\"]\n",
    "dataset_names = ['camelyon17-id', 'camelyon17-ood']\n",
    "\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, figuretitle=\"Conf-Acc Gap by Uncertainty for DenseNet121 on Camelyon17\")\n",
    "plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names)\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"camelyon17.pdf\"))\n",
    "plt.show()\n",
    "\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True, figuretitle=\"Conf-Acc Gap by Uncertainty for DenseNet121 on Camelyon17\")\n",
    "plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True)\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"camelyon17_TOPHALF.pdf\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution_directories = [#'./results/predictive_distributions/camelyon17/', # TODO or use:\n",
    "#                             './results/predictive_distributions/camelyon17_ts/', #TODO or use this one?\n",
    "#                             './results/predictive_distributions/camelyon17_ts_and_scaling_fitted']\n",
    "# distribution_names = [\"LLLA + TS(WI)\", \"LLLA + TS(WI) + Cov-scaling\"]\n",
    "# dataset_names = ['camelyon17-id', 'camelyon17-ood']\n",
    "\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, figuretitle=\"Conf-Acc Gap by Uncertainty for DenseNet121 on Camelyon17\")\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/camelyon17_model6/', # TODO or use:\n",
    "                            # './results/predictive_distributions/camelyon17_ts/', #TODO or use this one?\n",
    "                            './results/predictive_distributions/camelyon17_ts_and_scaling_fitted_model6']\n",
    "distribution_names = [\"LLLA\", \"LLLA+WITS+CVS\"]\n",
    "dataset_names = ['camelyon17-id', 'camelyon17-ood']\n",
    "\n",
    "plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, figuretitle=\"Conf-Acc Gap by Uncertainty for DenseNet121 on Camelyon17\")\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"camelyon17_model6.pdf\"))\n",
    "plt.show()\n",
    "\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True, figuretitle=\"Conf-Acc Gap by Uncertainty for DenseNet121 on Camelyon17\")\n",
    "plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True)\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"camelyon17_model6_TOPHALF.pdf\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution_directories = ['./results/predictive_distributions/camelyon17_resnet50/', # TODO or use:\n",
    "#                             # './results/predictive_distributions/camelyon17_ts/', #TODO or use this one?\n",
    "#                             './results/predictive_distributions/camelyon17_resnet50_ts_and_scaling_fitted']\n",
    "# distribution_names = [\"LLLA\", \"LLLA+WITS+CVS\"]\n",
    "# dataset_names = ['camelyon17-id', 'camelyon17-ood']\n",
    "\n",
    "# # plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True, figuretitle=\"Conf-Acc Gap by Uncertainty for ResNet50 on Camelyon17\")\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True)\n",
    "# plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"camelyon17_ResNet.pdf\"))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/amazon/',\n",
    "                            # './results/predictive_distributions/amazon_scaling/',\n",
    "                            # './results/predictive_distributions/amazon_ts/',\n",
    "                            './results/predictive_distributions/amazon_ts_and_scaling_fitted/',\n",
    "]\n",
    "distribution_names = [\"LLLA\", \"LLLA+WITS+CVS\"]\n",
    "dataset_names = ['amazon-id', 'amazon-ood']\n",
    "\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, figuretitle=\"Conf-Acc Gap by Uncertainty for DistilBERT on Amazon\")\n",
    "# plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"amazon.pdf\"))\n",
    "# plt.show()\n",
    "\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True, figuretitle=\"Conf-Acc Gap by Uncertainty for DistilBERT on Amazon\")\n",
    "plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True)\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"amazon_TOPHALF.pdf\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution_directories = [# './results/predictive_distributions/amazon/',\n",
    "#                             # './results/predictive_distributions/amazon_scaling/',\n",
    "#                             './results/predictive_distributions/amazon_ts/',\n",
    "#                             './results/predictive_distributions/amazon_ts_and_scaling_fitted/',\n",
    "# ]\n",
    "# distribution_names = [\"LLLA+WITS\", \"LLLA+WITS+CVS\"]\n",
    "# dataset_names = ['amazon-id', 'amazon-ood']\n",
    "\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkinLesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/SkinLesions/', # TODO or use:\n",
    "                            # './results/predictive_distributions/SkinLesions_ts/', #TODO or use this one?\n",
    "                            './results/predictive_distributions/SkinLesions_ts_and_scaling_fitted']\n",
    "\n",
    "distribution_names = [\"LLLA\", \"LLLA+WITS+CVS\"]\n",
    "dataset_names = ['SkinLesions-id', 'SkinLesions-ood']\n",
    "\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, figuretitle=\"Conf-Acc Gap by Uncertainty for ResNet50 on SkinLesions\")\n",
    "# plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"skinlesions.pdf\"))\n",
    "# plt.show()\n",
    "\n",
    "# plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True, figuretitle=\"Conf-Acc Gap by Uncertainty for ResNet50 on SkinLesions\")\n",
    "plot_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, dataset_names, justPlotTop=True, addXLabel=True)\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"skinlesions_TOPHALF.pdf\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, LeftToRight=True, figuretitle=''):\n",
    "    # LeftToRight allows to plot either Left to right (for view on Beamer) or if it is False, top to bottom (for pages)\n",
    "    # fig, axs = plt.subplots(3, 13)\n",
    "    if LeftToRight:\n",
    "        fig, axs = plt.subplots(3, 6)\n",
    "        # figsize = (plt.rcParams[\"figure.figsize\"][0], plt.rcParams[\"figure.figsize\"][0])\n",
    "        figsize = (8, 4.4)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        # fig, axs = plt.subplots(6, 3)\n",
    "        # # figsize = (plt.rcParams[\"figure.figsize\"][0], plt.rcParams[\"figure.figsize\"][0] * 2)\n",
    "        # figsize = (4, 8)\n",
    "\n",
    "    fig.set_size_inches(figsize)\n",
    "    # fig.set_size_inches(50, 10)\n",
    "\n",
    "    # TODO restrict figure to 6 ID/OOD conditions\n",
    "    for ax_jj, (DISTRIBUTIONS_DIRECTORY, distribution_name) in enumerate(zip(distribution_directories, distribution_names)):\n",
    "        ids = os.listdir(DISTRIBUTIONS_DIRECTORY)\n",
    "        ids = [i[7:-3] for i in ids if \"y_true_\" in i]\n",
    "        try:\n",
    "            ids = [int(i) for i in ids]\n",
    "            ids.sort()\n",
    "            ids = [str(i) for i in ids]\n",
    "        except:\n",
    "            pass\n",
    "        DATASET_LIST = ids\n",
    "        for ax_ii, DATASET in enumerate(DATASET_LIST):\n",
    "            if ax_ii >= 6:\n",
    "                pass\n",
    "            else:\n",
    "                if not LeftToRight:\n",
    "                    ax_i, ax_j = ax_jj, ax_ii # If plotting top to bottom, switch axis\n",
    "                else:\n",
    "                    ax_i, ax_j = ax_ii, ax_jj\n",
    "                print(\"### \", DISTRIBUTIONS_DIRECTORY, \" - \", DATASET)\n",
    "                y_true = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_true_\" + DATASET + \".pt\"))\n",
    "                # y_prob = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_prob_\" + DATASET + \".pt\"))\n",
    "\n",
    "                f_mu = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_mu_\" + DATASET + \".pt\"))\n",
    "                f_var = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_var_\" + DATASET + \".pt\"))\n",
    "\n",
    "\n",
    "                confs, preds, variances, y_pred = calculate_confs_preds_variances_ypreds(f_mu, f_var, y_true)\n",
    "\n",
    "                ax = axs[ax_j][ax_i]\n",
    "                plot_conf_acc_gap_by_uncertainty_to_ax(ax, y_pred, variances, y_true, n_bins=100, marker='.')\n",
    "                if LeftToRight:\n",
    "                    DATASET_STRING = \"0 (ID)\" if DATASET == \"0\" else DATASET\n",
    "                    if ax_j == 0 or ax_j == 1:\n",
    "                        ax.set_title(f'Rotation: {DATASET_STRING}')\n",
    "                    if ax_j == 2:\n",
    "                        ax.set_title(f'Corruption: {DATASET_STRING}')\n",
    "                    if ax_i == 0:\n",
    "                        ax.set_ylabel(distribution_name + \"\\n\" + r'$\\vert$Conf - Acc$\\vert$')\n",
    "                    if ax_j == 2:\n",
    "                        ax.set_xlabel(r\"$2 \\sigma$ of conf mean\")\n",
    "                else:\n",
    "                    pass # TODO\n",
    "                    # if ax_j == 0:\n",
    "                    #     ax.set_title(distribution_name)\n",
    "                    # if ax_i == 0:\n",
    "                    #     ax.set_ylabel(r'$\\vert$Conf - Acc$\\vert$')\n",
    "    fig.suptitle(figuretitle)\n",
    "    # plt.savefig(\"plotting_uncertainty_pr/acc_gap_by_uncertainty/toy_datasets.png\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO remove testing\n",
    "# distribution_directories = ['./results/predictive_distributions/R-MNIST',\n",
    "#                             # './results/predictive_distributions/R-MNIST_scaling',\n",
    "#                             # './results/predictive_distributions/R-MNIST_ts',\n",
    "#                             # './results/predictive_distributions/R-MNIST_ts_scaling',\n",
    "#                             './results/predictive_distributions/R-FMNIST',\n",
    "#                             # './results/predictive_distributions/R-FMNIST_scaling',\n",
    "#                             # './results/predictive_distributions/R-FMNIST_ts',\n",
    "#                             # './results/predictive_distributions/R-FMNIST_ts_scaling',\n",
    "#                             './results/predictive_distributions/CIFAR-10-C',\n",
    "#                             # './results/predictive_distributions/CIFAR-10-C_scaling',\n",
    "#                             # './results/predictive_distributions/CIFAR-10-C_ts',\n",
    "#                             # './results/predictive_distributions/CIFAR-10-C_ts_scaling',\n",
    "# ]\n",
    "\n",
    "# distribution_names = [\"R-MNIST\", \"R-FMNIST\", \"CIFAR-10-C\"]\n",
    "\n",
    "\n",
    "# plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, LeftToRight=True, figuretitle='Conf-Acc Gap by Uncertainty\\nfor R-MNIST, R-FMNIST and CIFAR-10-C')\n",
    "# plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"toy_datasets.pdf\"))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/R-MNIST',\n",
    "                            # './results/predictive_distributions/R-MNIST_scaling',\n",
    "                            # './results/predictive_distributions/R-MNIST_ts',\n",
    "                            # './results/predictive_distributions/R-MNIST_ts_scaling',\n",
    "                            './results/predictive_distributions/R-FMNIST',\n",
    "                            # './results/predictive_distributions/R-FMNIST_scaling',\n",
    "                            # './results/predictive_distributions/R-FMNIST_ts',\n",
    "                            # './results/predictive_distributions/R-FMNIST_ts_scaling',\n",
    "                            './results/predictive_distributions/CIFAR-10-C',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C_scaling',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C_ts',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C_ts_scaling',\n",
    "]\n",
    "\n",
    "distribution_names = [\"R-MNIST\", \"R-FMNIST\", \"CIFAR-10-C\"]\n",
    "\n",
    "\n",
    "# plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, figuretitle='Conf-Acc Gap by Uncertainty for R-MNIST, R-FMNIST and CIFAR-10-C')\n",
    "plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names)\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"toy_datasets.pdf\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = [#'./results/predictive_distributions/R-MNIST',\n",
    "                            './results/predictive_distributions/R-MNIST_scaling',\n",
    "                            # './results/predictive_distributions/R-MNIST_ts',\n",
    "                            # './results/predictive_distributions/R-MNIST_ts_scaling',\n",
    "                            # './results/predictive_distributions/R-FMNIST',\n",
    "                            './results/predictive_distributions/R-FMNIST_scaling',\n",
    "                            # './results/predictive_distributions/R-FMNIST_ts',\n",
    "                            # './results/predictive_distributions/R-FMNIST_ts_scaling',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C',\n",
    "                            './results/predictive_distributions/CIFAR-10-C_scaling',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C_ts',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C_ts_scaling',\n",
    "]\n",
    "\n",
    "distribution_names = [\"R-MNIST\", \"R-FMNIST\", \"CIFAR-10-C\"]\n",
    "\n",
    "\n",
    "# plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, figuretitle='Conf-Acc Gap by Uncertainty for R-MNIST, R-FMNIST and CIFAR-10-C using CVS')\n",
    "plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names)\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"toy_datasets_CVS.pdf\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = [#'./results/predictive_distributions/R-MNIST',\n",
    "                            # './results/predictive_distributions/R-MNIST_scaling',\n",
    "                            './results/predictive_distributions/R-MNIST_ts',\n",
    "                            # './results/predictive_distributions/R-MNIST_ts_scaling',\n",
    "                            # './results/predictive_distributions/R-FMNIST',\n",
    "                            # './results/predictive_distributions/R-FMNIST_scaling',\n",
    "                            './results/predictive_distributions/R-FMNIST_ts',\n",
    "                            # './results/predictive_distributions/R-FMNIST_ts_scaling',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C_scaling',\n",
    "                            './results/predictive_distributions/CIFAR-10-C_ts',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C_ts_scaling',\n",
    "]\n",
    "\n",
    "distribution_names = [\"R-MNIST\", \"R-FMNIST\", \"CIFAR-10-C\"]\n",
    "\n",
    "# plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, figuretitle='Conf-Acc Gap by Uncertainty for R-MNIST, R-FMNIST and CIFAR-10-C using WITS')\n",
    "plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names)\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"toy_datasets_WITS.pdf\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = [#'./results/predictive_distributions/R-MNIST',\n",
    "                            # './results/predictive_distributions/R-MNIST_scaling',\n",
    "                            # './results/predictive_distributions/R-MNIST_ts',\n",
    "                            './results/predictive_distributions/R-MNIST_ts_scaling',\n",
    "                            # './results/predictive_distributions/R-FMNIST',\n",
    "                            # './results/predictive_distributions/R-FMNIST_scaling',\n",
    "                            # './results/predictive_distributions/R-FMNIST_ts',\n",
    "                            './results/predictive_distributions/R-FMNIST_ts_scaling',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C_scaling',\n",
    "                            # './results/predictive_distributions/CIFAR-10-C_ts',\n",
    "                            './results/predictive_distributions/CIFAR-10-C_ts_scaling',\n",
    "]\n",
    "\n",
    "distribution_names = [\"R-MNIST\", \"R-FMNIST\", \"CIFAR-10-C\"]\n",
    "\n",
    "# plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names, figuretitle='Conf-Acc Gap by Uncertainty for R-MNIST, R-FMNIST and CIFAR-10-C using WITS+CVS')\n",
    "plot_ToyDatasets_conf_acc_gap_by_uncertainty_plot(distribution_directories, distribution_names)\n",
    "plt.savefig(os.path.join(savedir_confAccGapByUncertainty, \"toy_datasets_WITS_CVS.pdf\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "af0c9fde4027a6d12ce721ddc579f510a33aad884d5d9cd2cd9b181ef5a6dae5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
