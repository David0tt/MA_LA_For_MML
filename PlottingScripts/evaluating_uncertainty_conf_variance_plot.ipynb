{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import pycalib\n",
    "from laplace import Laplace\n",
    "\n",
    "import utils.data_utils as du\n",
    "import utils.wilds_utils as wu\n",
    "import utils.utils as util\n",
    "from utils.test import test\n",
    "from marglik_training.train_marglik import get_backend\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tueplots import bundles\n",
    "\n",
    "\n",
    "\n",
    "# Inspired by bundles.neurips2023(), but adapting font sizes for pt12 standard\n",
    "\n",
    "settings_dict = {'text.usetex': True,\n",
    "                 'font.family': 'serif',\n",
    "                 'text.latex.preamble': '\\\\renewcommand{\\\\rmdefault}{ptm}\\\\renewcommand{\\\\sfdefault}{phv}',\n",
    "                 'figure.figsize': (5.5, 3.399186938124422),\n",
    "                 'figure.constrained_layout.use': True,\n",
    "                 'figure.autolayout': False,\n",
    "                 'savefig.bbox': 'tight',\n",
    "                 'savefig.pad_inches': 0.015,\n",
    "                 'font.size': 10,\n",
    "                 'axes.labelsize': 10,\n",
    "                 'legend.fontsize': 8,\n",
    "                 'xtick.labelsize': 8,\n",
    "                 'ytick.labelsize': 8,\n",
    "                 'axes.titlesize': 10,\n",
    "                 'figure.dpi': 300}\n",
    "\n",
    "\n",
    "plt.rcParams.update(settings_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Can use colors from bundles.rgb.\n",
    "#     tue_blue\n",
    "#     tue_brown\n",
    "#     tue_dark\n",
    "#     tue_darkblue\n",
    "#     tue_darkgreen\n",
    "#     tue_gold\n",
    "#     tue_gray\n",
    "#     tue_green\n",
    "#     tue_lightblue\n",
    "#     tue_lightgold\n",
    "#     tue_lightgreen\n",
    "#     tue_lightorange\n",
    "#     tue_mauve\n",
    "#     tue_ocre\n",
    "#     tue_orange\n",
    "#     tue_red\n",
    "#     tue_violet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def invImageNetNorm(x):\n",
    "    \"\"\" Inverts the Normalization given by:\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]) \"\"\"\n",
    "    invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "    return invTrans(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cov(points):\n",
    "    B, N, D = points.size()\n",
    "    mean = points.mean(dim=1).unsqueeze(1)\n",
    "    diffs = (points - mean).reshape(B * N, D)\n",
    "    prods = torch.bmm(diffs.unsqueeze(2), diffs.unsqueeze(1)).reshape(B, N, D, D)\n",
    "    bcov = prods.sum(dim=1) / (N - 1)  # Unbiased estimate\n",
    "    return bcov  # (B, D, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_samples(mean, var, n_samples, generator=None):\n",
    "    \"\"\"Produce samples from a batch of Normal distributions either parameterized\n",
    "    by a diagonal or full covariance given by `var`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : torch.Tensor\n",
    "        `(batch_size, output_dim)`\n",
    "    var : torch.Tensor\n",
    "        (co)variance of the Normal distribution\n",
    "        `(batch_size, output_dim, output_dim)` or `(batch_size, output_dim)`\n",
    "    generator : torch.Generator\n",
    "        random number generator\n",
    "    \"\"\"\n",
    "    assert mean.ndim == 2, 'Invalid input shape of mean, should be 2-dimensional.'\n",
    "    _, output_dim = mean.shape\n",
    "    randn_samples = torch.randn((output_dim, n_samples), device=mean.device, \n",
    "                                dtype=mean.dtype, generator=generator)\n",
    "    \n",
    "    if mean.shape == var.shape:\n",
    "        # diagonal covariance\n",
    "        scaled_samples = var.sqrt().unsqueeze(-1) * randn_samples.unsqueeze(0)\n",
    "        return (mean.unsqueeze(-1) + scaled_samples).permute((2, 0, 1))\n",
    "    elif mean.shape == var.shape[:2] and var.shape[-1] == mean.shape[1]:\n",
    "        # full covariance\n",
    "        scale = torch.linalg.cholesky(var)\n",
    "        scaled_samples = torch.matmul(scale, randn_samples.unsqueeze(0))  # expand batch dim\n",
    "        return (mean.unsqueeze(-1) + scaled_samples).permute((2, 0, 1))\n",
    "    else:\n",
    "        raise ValueError('Invalid input shapes.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_testloader(dataset):\n",
    "    if dataset == 'camelyon17-id':\n",
    "        dataset = 'camelyon17'\n",
    "        train_loader, val_loader, in_test_loader = wu.get_wilds_loaders(\n",
    "            dataset, './data', 1.0, 1, download=False, use_ood_val_set=False)\n",
    "        test_loader = in_test_loader\n",
    "    elif dataset == 'camelyon17-ood':\n",
    "        dataset = 'camelyon17'\n",
    "        test_loader = wu.get_wilds_ood_test_loader(\n",
    "            dataset, './data', 1.0)\n",
    "    elif dataset == 'SkinLesions-id':\n",
    "        train_loader, val_loader, test_loader = du.get_ham10000_loaders('./data', batch_size=16, train_batch_size=16, num_workers=4, image_size=512)\n",
    "    elif dataset == 'SkinLesions-ood':\n",
    "        test_loader = du.get_SkinLesions_ood_loader(None, data_path='./data', batch_size=16, num_workers=4, image_size=512)\n",
    "    return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_testloader_order(test_loader, y_true):\n",
    "    ''' Check, that the labels produced by the test_loader match the order of y_true. \n",
    "        This should assert, that the predictions used here do in fact match the images produced by the test_loader\n",
    "    '''\n",
    "    y_true_testloader = []\n",
    "\n",
    "    for _, y in test_loader:\n",
    "        y_true_testloader.append(y)\n",
    "    y_true_testloader = torch.cat(y_true_testloader)\n",
    "    assert torch.all(y_true_testloader == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confs_preds_variances(f_mu, f_var, y_true, n_samples = 10000, generator = None, batchsize = 128):\n",
    "    # For all images, calculate the conf and covariance\n",
    "    # To do this sample from distribution\n",
    "\n",
    "    confs_list = []\n",
    "    preds_list = []\n",
    "    variances_list = []\n",
    "\n",
    "    s_list = list(range(0, y_true.shape[0] + batchsize, batchsize))\n",
    "    # s_list = list(range(0, 1000, batchsize))\n",
    "    for start, stop in tqdm(zip(s_list[:-1], s_list[1:])):\n",
    "        f_mu_now = f_mu[start:stop]\n",
    "        f_var_now = f_var[start:stop]\n",
    "        \n",
    "        f_samples = normal_samples(f_mu_now, f_var_now, n_samples, generator)\n",
    "        y_prob = torch.softmax(f_samples, dim=-1)\n",
    "\n",
    "        covariances = batch_cov(y_prob.permute(1,0,2))\n",
    "\n",
    "        y_pred = y_prob.mean(dim=0)\n",
    "\n",
    "        confs, preds = torch.max(y_pred, 1)\n",
    "\n",
    "        variances = torch.tensor([c[preds[i], preds[i]] for i, c in enumerate(covariances)])\n",
    "\n",
    "        confs_list.append(confs)\n",
    "        preds_list.append(preds)\n",
    "        variances_list.append(variances)\n",
    "\n",
    "    confs_list = torch.cat(confs_list)\n",
    "    preds_list = torch.cat(preds_list)\n",
    "    variances_list = torch.cat(variances_list)\n",
    "\n",
    "    return confs_list, preds_list, variances_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_variance(confs, variances, title_string = '', alpha = 0.05):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(confs.numpy(), variances.numpy(), alpha=alpha)\n",
    "    ax.set_xlabel(\"confidence\")\n",
    "    ax.set_ylabel(\"variances\")\n",
    "    plt.title(title_string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DISTRIBUTIONS_DIRECTORY = './results/predictive_distributions/camelyon17_model6/'\n",
    "# # DISTRIBUTIONS_DIRECTORY = './results/predictive_distributions/camelyon17_resnet50/'\n",
    "# DISTRIBUTIONS_DIRECTORY = './results/predictive_distributions/camelyon17_wrn50/'\n",
    "\n",
    "# # DISTRIBUTIONS_DIRECTORY = \"/mnt/j/Results_Predictive_Distributions/camelyon17_ts_and_scaling_fitted\"\n",
    "\n",
    "\n",
    "# # DATASET = 'camelyon17-id' # 'camelyon17-ood'\n",
    "# DATASET = 'camelyon17-ood'\n",
    "\n",
    "# # images = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"x_\" + DATASET + \".pt\"))\n",
    "# y_true = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_true_\" + DATASET + \".pt\"))\n",
    "# # y_prob = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"y_prob_\" + DATASET + \".pt\"))\n",
    "\n",
    "# f_mu = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_mu_\" + DATASET + \".pt\"))\n",
    "# f_var = torch.load(os.path.join(DISTRIBUTIONS_DIRECTORY, \"f_var_\" + DATASET + \".pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = get_appropriate_testloader(DATASET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_testloader_order(test_loader, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confs, preds, variances = calculate_confs_preds_variances(f_mu, f_var, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_conf_variance(confs, variances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same with variance from logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_variances = torch.tensor([c[preds[i], preds[i]] for i, c in enumerate(f_var)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(confs.numpy(), logit_variances.numpy(), alpha=0.05)\n",
    "# ax.set_xlabel(\"confs\")\n",
    "# ax.set_ylabel(\"variances\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot images into plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.rcParams[\"figure.dpi\"] = 300\n",
    "# from matplotlib import rc\n",
    "# rc('text', usetex=True)\n",
    "matplotlib.rc('text', usetex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "def add_cross_to_image(image, color=None, width=1):\n",
    "    ''' Add a cross to the center of an image'''\n",
    "    img = Image.fromarray(np.uint8(image*255))\n",
    "    img1 = ImageDraw.Draw(img)\n",
    "    img1.line([(0, 0), (img.width, img.height)], width=width, fill=color)\n",
    "    img1.line([(img.width, 0), (0, img.height)], width=width, fill=color)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NAIVE: just produce an images array as it previously was:\n",
    "# images = []\n",
    "\n",
    "# for x, _ in test_loader:\n",
    "#     images.append(x)\n",
    "# images = torch.cat(images)\n",
    "# images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that loader.dataset has the same order:\n",
    "\n",
    "def check_loader_dataset_order(test_loader, y_true):\n",
    "    ''' Test, whether the labels produced by test_loader.dataset[i] have the same order as the ones given by y_true\n",
    "        This should assert, that the images do in fact match the predictions that have been made\n",
    "    '''\n",
    "    labels = []\n",
    "    if len(test_loader.dataset[0]) == 3:\n",
    "        for i in range(len(y_true)):\n",
    "            x, y, _ = test_loader.dataset[i]\n",
    "            labels.append(y.reshape((1)))\n",
    "    elif len(test_loader.dataset[0]) == 2:\n",
    "        for i in range(len(y_true)):\n",
    "            x, y = test_loader.dataset[i]\n",
    "            y = torch.asarray(y)\n",
    "            labels.append(y.reshape((1)))\n",
    "\n",
    "\n",
    "    labels = torch.cat(labels)\n",
    "\n",
    "    assert torch.all(labels == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_loader_dataset_order(test_loader, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(sample_ids, loader):\n",
    "    ''' Return an array with the images specified by sample_ids '''\n",
    "    images = []\n",
    "    for id in sample_ids:\n",
    "        id = int(id)\n",
    "        x = loader.dataset[id][0]\n",
    "        images.append(x.unsqueeze(0))\n",
    "    images = torch.cat(images)\n",
    "    return images\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_ids_gridfilling(x, y, IMAGES_SUBSET):\n",
    "\n",
    "    # TODO normalize\n",
    "    # As grid axis can be very different, we need to normalize:\n",
    "    # make x_min and x_max to [0,1] and y_min, y_max to [0, 1]\n",
    "    # sbutract x_min from all. Then divide by new maximum\n",
    "\n",
    "    x_limits = [x.min(), x.max()]\n",
    "    y_limits = [y.min(), y.max()]\n",
    "\n",
    "    x = x - x.min()\n",
    "    x = x / x.max()\n",
    "\n",
    "    y = y - y.min()\n",
    "    y = y / y.max()\n",
    "\n",
    "\n",
    "    # Since the plots are not quadratic, we need to put the points on the grid\n",
    "    # in such a way that they are equally spaced\n",
    "    # (5.5, 3.399186938124422)\n",
    "    proportion_XY = 5.5 / 3.399186938124422\n",
    "    num_images_y = np.sqrt((IMAGES_SUBSET / proportion_XY))\n",
    "    num_images_x = num_images_y * proportion_XY\n",
    "\n",
    "    x_grid = torch.linspace(x.min(), x.max(), int(num_images_x))\n",
    "    y_grid = torch.linspace(y.min(), y.max(), int(num_images_y))\n",
    "    xv, yv = torch.meshgrid(x_grid, y_grid)\n",
    "\n",
    "    # Testing\n",
    "    # plt.scatter(xv, yv)\n",
    "    # plt.show()\n",
    "\n",
    "    xv, yv = xv.flatten(), yv.flatten()\n",
    "\n",
    "    gridpoints = torch.vstack([xv, yv]).transpose(0, 1)\n",
    "    xy = torch.vstack([x, y]).transpose(0, 1)\n",
    "    gridpoints, xy = gridpoints.unsqueeze(0), xy.unsqueeze(0)\n",
    "    dists, ids = torch.cdist(xy, gridpoints, p=2).squeeze().min(0)\n",
    "\n",
    "\n",
    "    # # Testing\n",
    "    # gridpoints = gridpoints.squeeze()\n",
    "    # xy = xy.squeeze()\n",
    "    # for gridpoint, xy_point in zip(gridpoints, xy[ids]):\n",
    "    #     plt.plot([gridpoint[0], xy_point[0]], [gridpoint[1], xy_point[1]])\n",
    "    # plt.show()\n",
    "\n",
    "    # # Testing\n",
    "    # plt.scatter(x, y, color='red')\n",
    "    # plt.scatter(x[ids], y[ids])\n",
    "    # plt.show()\n",
    "    \n",
    "    return torch.unique(ids), x_limits, y_limits \n",
    "\n",
    "\n",
    "# TESTING\n",
    "# x = confs\n",
    "# y = variances\n",
    "\n",
    "# TESTING\n",
    "# x = torch.asarray([1, 5, 1.5, 3.5, 1.5, 2.5])\n",
    "# y = torch.asarray([1, 5, 1.5, 3.5, 4.5, 4.5])\n",
    "\n",
    "# y = logit_variances\n",
    "# ALL_SAMPLE_IDS = torch.tensor(list(range(len(y_true))))\n",
    "# sample_ids = ALL_SAMPLE_IDS\n",
    "# sample_ids = find_image_ids_gridfilling(x, y, IMAGES_SUBSET)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CrossedSquarePatch(object):\n",
    "    def __init__(self, color = 'red', crossed = False):\n",
    "        self.color = color\n",
    "        self.crossed = crossed\n",
    "\n",
    "class CrossedSquarePatchHandler(object):\n",
    "    def legend_artist(self, legend, orig_handle, fontsize, handlebox):\n",
    "        x0, y0 = handlebox.xdescent, handlebox.ydescent\n",
    "        width, height = handlebox.width, handlebox.height\n",
    "        patch = mpatches.Rectangle([x0, y0], width, height, fill=None,\n",
    "                                   edgecolor=orig_handle.color,\n",
    "                                   transform=handlebox.get_transform())\n",
    "        handlebox.add_artist(patch)\n",
    "\n",
    "        if orig_handle.crossed:\n",
    "            Path = mpath.Path\n",
    "            path_data = [\n",
    "                (Path.MOVETO, (x0, y0)),\n",
    "                (Path.LINETO, (width, height)),\n",
    "                (Path.MOVETO, (width, y0)),\n",
    "                (Path.LINETO, (x0, height)),\n",
    "                ]\n",
    "            codes, verts = zip(*path_data)\n",
    "            path = mpath.Path(verts, codes)\n",
    "            path_patch = mpatches.PathPatch(path, edgecolor=orig_handle.color, fill=None, alpha=1)\n",
    "            handlebox.add_artist(path_patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_var_gridfilling(confs, variances, test_loader, preds, y_true, title_string = '', images_subset = 200, dataset = 'camelyon17'):\n",
    "    x = confs\n",
    "    y = variances\n",
    "    sample_ids, x_limits, y_limits = find_image_ids_gridfilling(x, y, images_subset)\n",
    "\n",
    "    print(\"x_limits: \", x_limits)\n",
    "    print(\"y_limits: \", y_limits)\n",
    "    \n",
    "\n",
    "    x = x.numpy()[sample_ids]\n",
    "    y = y.numpy()[sample_ids]\n",
    "    imgs = get_images(sample_ids, test_loader)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    # ax.set_xlim(x_limits)\n",
    "    # ax.set_ylim(y_limits)\n",
    "\n",
    "    ax.scatter(x, y) \n",
    "    for x0, y0, img, sample_id in zip(x, y, imgs, sample_ids):\n",
    "        img = invImageNetNorm(img).permute(1,2,0)\n",
    "\n",
    "        # green border for 0, red border for 1\n",
    "        # x if it is wrongly classified\n",
    "        if dataset == 'camelyon17':\n",
    "            # my_green = matplotlib.colors.to_hex(tuple(bundles.rgb.tue_green))\n",
    "            # my_red = matplotlib.colors.to_hex(tuple(bundles.rgb.tue_red))\n",
    "            my_green, my_red = 'green', '#CB0000'\n",
    "            class_to_color = {0: my_green, 1: my_red}\n",
    "            zoom = 0.22\n",
    "        elif dataset == 'SkinLesions':\n",
    "            class_to_color = {0: 'green', 1: 'red', 2: 'blue', 3: 'orange', 4: 'pink', 5: 'yellow', 6: 'violet', 7: 'lightblue'}\n",
    "            zoom = 0.045\n",
    "\n",
    "        true_class = int(y_true[sample_id])\n",
    "\n",
    "        BorderWidth = 2\n",
    "        LineWidth = 6\n",
    "        if dataset == 'camelyon17':\n",
    "            BorderWidth = 2\n",
    "            LineWidth = 5\n",
    "        if dataset == 'SkinLesions':\n",
    "            BorderWidth = 2\n",
    "            LineWidth = 20\n",
    "\n",
    "        bboxprops = dict(edgecolor=class_to_color[true_class], linewidth=BorderWidth)\n",
    "        if preds[sample_id] != y_true[sample_id]:\n",
    "            img = add_cross_to_image(img, color=class_to_color[true_class], width=LineWidth)\n",
    "        \n",
    "        img = OffsetImage(img, zoom=zoom)\n",
    "\n",
    "        ab = AnnotationBbox(img, (x0, y0), frameon=True, pad=0, bboxprops=bboxprops)\n",
    "        ax.add_artist(ab)\n",
    "    plt.xlabel('confidence')\n",
    "    # plt.ylabel(r'$\\leftarrow$ aleatoric uncertainty $\\leftarrow$ ~~~~~~~~~~ \\textbf{variance} ~~~~~~~~~~ $\\rightarrow$ epistemic uncertatinty $\\rightarrow$')\n",
    "    plt.ylabel(r'$\\leftarrow$ aleatoric $\\leftarrow$ ~~~ \\textbf{variance} ~~~ $\\rightarrow$ epistemic $\\rightarrow$')\n",
    "\n",
    "    if dataset == \"camelyon17\":\n",
    "        plt.legend([CrossedSquarePatch(my_green, False),\n",
    "                    CrossedSquarePatch(my_red, False),\n",
    "                    CrossedSquarePatch(my_green, True),\n",
    "                    CrossedSquarePatch(my_red, True)], \n",
    "                    # ['Class = 0 - No Tumor; Correctly Classified',\n",
    "                    # 'Class = 1 - Tumor; Correctly Classified',\n",
    "                    # 'true Class = 0; Predicted = 1; Misclassified',\n",
    "                    # 'true Class = 1; Predicted = 0; Misclassified'],\n",
    "                    ['Normal; Correctly Classified',\n",
    "                    'Tumor; Correctly Classified',\n",
    "                    'Normal; Misclassified as Tumor',\n",
    "                    'Tumor; Misclassified as Normal'],\n",
    "                handler_map={CrossedSquarePatch: CrossedSquarePatchHandler()}, handlelength = 0.7, handleheight = 0.7, fontsize = 'large')\n",
    "    if dataset == \"SkinLesions\":\n",
    "        plt.legend([CrossedSquarePatch('black', False),\n",
    "                    CrossedSquarePatch('black', True)],\n",
    "                    ['Correctly Classified',\n",
    "                    'Misclassified'],\n",
    "                handler_map={CrossedSquarePatch: CrossedSquarePatchHandler()}, handlelength = 0.7, handleheight = 0.7, fontsize = 'large')\n",
    "\n",
    "    plt.title(title_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_conf_var_gridfilling(confs, variances, title_string = '', images_subset = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/camelyon17_model6/',\n",
    "                            './results/predictive_distributions/camelyon17_resnet50/',\n",
    "                            './results/predictive_distributions/camelyon17_wrn50/']\n",
    "\n",
    "model_strings = ['densenet121', 'resnet50', 'wrn50']\n",
    "\n",
    "savedir = './results/images/img/ConfVariancePlots'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "for distribution_directory, model_string in zip(distribution_directories, model_strings):\n",
    "    for dataset in ['camelyon17-id', 'camelyon17-ood']:\n",
    "        y_true = torch.load(os.path.join(distribution_directory, \"y_true_\" + dataset + \".pt\"))\n",
    "        f_mu = torch.load(os.path.join(distribution_directory, \"f_mu_\" + dataset + \".pt\"))\n",
    "        f_var = torch.load(os.path.join(distribution_directory, \"f_var_\" + dataset + \".pt\"))\n",
    "\n",
    "        test_loader = get_appropriate_testloader(dataset)\n",
    "        \n",
    "        # TODO checks can also be omitted if everything works\n",
    "        # check_loader_dataset_order(test_loader, y_true)\n",
    "        # check_testloader_order(test_loader, y_true)\n",
    "\n",
    "        confs, preds, variances = calculate_confs_preds_variances(f_mu, f_var, y_true)\n",
    "\n",
    "        ModelStringConversion = {'densenet121': 'DenseNet121', 'resnet50': 'ResNet50', 'wrn50': 'WideResNet50'}\n",
    "        DatasetStringConversion = {'camelyon17-id': 'Camelyon17 (ID)', 'camelyon17-ood': 'Camelyon17 (OOD)'}\n",
    "        title_string = f'Uncertainty of {ModelStringConversion[model_string]} on {DatasetStringConversion[dataset]}'\n",
    "\n",
    "        plot_conf_variance(confs, variances, title_string=title_string)\n",
    "\n",
    "        plot_conf_var_gridfilling(confs, variances, test_loader, preds, y_true, title_string = title_string, images_subset = 100)\n",
    "\n",
    "        plt.savefig(os.path.join(savedir, f'{model_string}_{dataset}.pdf'))\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO modify plotting code to not have a plt.show()\n",
    "# if not os.path.exists('img/Results/ToyData_ECE_NLL/'):\n",
    "#     os.makedirs('img/Results/ToyData_ECE_NLL/')\n",
    "# plt.savefig('img/Results/ToyData_ECE_NLL/MAP_LLLA_TS_ECE_NLL.pdf')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkinLesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_directories = ['./results/predictive_distributions/SkinLesions/',\n",
    "                            './results/predictive_distributions/SkinLesions_wrn50/']\n",
    "\n",
    "model_strings = ['resnet50', 'wrn50']\n",
    "\n",
    "savedir = './results/images/img/ConfVariancePlots'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "\n",
    "for distribution_directory, model_string in zip(distribution_directories, model_strings):\n",
    "    for dataset in ['SkinLesions-id', 'SkinLesions-ood']:\n",
    "        y_true = torch.load(os.path.join(distribution_directory, \"y_true_\" + dataset + \".pt\"))\n",
    "        f_mu = torch.load(os.path.join(distribution_directory, \"f_mu_\" + dataset + \".pt\"))\n",
    "        f_var = torch.load(os.path.join(distribution_directory, \"f_var_\" + dataset + \".pt\"))\n",
    "\n",
    "        test_loader = get_appropriate_testloader(dataset)\n",
    "        \n",
    "        # TODO checks can also be omitted if everything works\n",
    "        # check_loader_dataset_order(test_loader, y_true)\n",
    "        # check_testloader_order(test_loader, y_true)\n",
    "\n",
    "        confs, preds, variances = calculate_confs_preds_variances(f_mu, f_var, y_true)\n",
    "\n",
    "        ModelStringConversion = {'densenet121': 'DenseNet121', 'resnet50': 'ResNet50', 'wrn50': 'WideResNet50'}\n",
    "        DatasetStringConversion = {'camelyon17-id': 'Camelyon17 (ID)', 'camelyon17-ood': 'Camelyon17 (OOD)', 'SkinLesions-id': 'SkinLesions (ID)', 'SkinLesions-ood': 'SkinLesions (OOD)'}\n",
    "        title_string = f'Uncertainty of {ModelStringConversion[model_string]} on {DatasetStringConversion[dataset]}'\n",
    "\n",
    "        plot_conf_variance(confs, variances, title_string=title_string)\n",
    "\n",
    "        plot_conf_var_gridfilling(confs, variances, test_loader, preds, y_true, title_string = title_string, images_subset = 100, dataset='SkinLesions')\n",
    "\n",
    "        plt.savefig(os.path.join(savedir, f'{model_string}_{dataset}.pdf'))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "af0c9fde4027a6d12ce721ddc579f510a33aad884d5d9cd2cd9b181ef5a6dae5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
